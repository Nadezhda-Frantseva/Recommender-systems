# -*- coding: utf-8 -*-
"""BookRecommender.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iNdDvF4sxdkC8wWyGNPG990oPSoiFa_5
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"
# %cd /content/gdrive/My Drive/Kaggle

# Download and unzip the dataset
!kaggle datasets download -d zygmunt/goodbooks-10k
!ls
!unzip \*.zip  && rm *.zip

# Import necessary libraries and load the data
import pandas as pd

data = pd.read_csv('/content/gdrive/My Drive/Kaggle/ratings.csv')
print(data)

# Handle missing values and display data information
data = data.fillna(data.mean())
data.info()

data.describe()

!pip install surprise

!pip install scikit-surprise

import time
import datetime
from tabulate import tabulate
from surprise import SVD, SVDpp, KNNBasic, SlopeOne, CoClustering
from surprise import Dataset
from surprise import Reader
from surprise.model_selection import cross_validate

# Load data into Surprise's dataset format
reader = Reader(rating_scale=(1, 5))
df_data = Dataset.load_from_df(data[['user_id', 'book_id', 'rating']], reader)

print(data.head())

trainset = df_data.build_full_trainset()
print('Number of users:', trainset.n_users)
print('Number of items:', trainset.n_items)
print('Number of ratings:', trainset.n_ratings)

import numpy as np
# Function to evaluate and print results
def evaluate_algorithms(algorithms, df_data, reg_all=None):
    table = []
    for algorithm in algorithms:
        start = time.time()
        algo_instance = algorithm() if reg_all is None else algorithm(reg_all=reg_all)
        result = cross_validate(algo_instance, df_data, measures=['RMSE', 'MAE'], cv=5, verbose=True)
        execution_time = str(datetime.timedelta(seconds=int(time.time() - start)))
        mean_rmse = '{:.3f}'.format(np.mean(result['test_rmse']))
        mean_mae = '{:.3f}'.format(np.mean(result['test_mae']))
        calculation = [algorithm.__name__, mean_rmse, mean_mae, execution_time]
        table.append(calculation)
    header = ['Collaborative Filtering Algorithms', 'RMSE', 'MAE', 'Time']
    print(tabulate(table, header, tablefmt="psql"))

# Experiment 1
collaborative_filtering_algorithms = (SlopeOne, CoClustering, SVD, SVDpp)
evaluate_algorithms(collaborative_filtering_algorithms, df_data)

# Experiment 2
basic_algorithms = (SlopeOne, CoClustering)
svd_algorithms = (SVD, SVDpp)
evaluate_algorithms(basic_algorithms, df_data)
evaluate_algorithms(svd_algorithms, df_data, reg_all=0.1)

# Experiment 3
evaluate_algorithms(basic_algorithms, df_data)
evaluate_algorithms(svd_algorithms, df_data, reg_all=0.5)

# Experiment 4
evaluate_algorithms(basic_algorithms, df_data)
evaluate_algorithms(svd_algorithms, df_data, reg_all=0.85)

# Function to get top recommendations
from surprise.model_selection import train_test_split
from surprise import accuracy
from collections import defaultdict

def get_top_recommendations(predictions, n=5):
    top_results = defaultdict(list)
    for user_id, item_id, true_r, est, _ in predictions:
        top_results[user_id].append((item_id, est))
    for user_id, user_ratings in top_results.items():
        user_ratings.sort(key=lambda x: x[1], reverse=True)
        top_results[user_id] = user_ratings[:n]
    return top_results

# Train and test the algorithm, and get top recommendations
trainset, testset = train_test_split(df_data, test_size=0.25, random_state=12)
algorithm = SVDpp().fit(trainset)
predictions = algorithm.test(testset)
accuracy.rmse(predictions)
top_results = get_top_recommendations(predictions, n=10)

# Load books data and display top recommendations
books_df = pd.read_csv('books.csv')
book_id_to_name = pd.Series(books_df.title.values, index=books_df['id']).to_dict()
top_results = get_top_recommendations(predictions, n=5)
for user_id, user_ratings in top_results.items():
    recommended_books = [book_id_to_name.get(item_id, "Unknown Book") for (item_id, _) in user_ratings]
    print(user_id, recommended_books)

!pip install lightfm

from lightfm import LightFM
from lightfm.data import Dataset
from lightfm.evaluation import precision_at_k
from lightfm.cross_validation import random_train_test_split

data = data.groupby(['user_id', 'book_id']).rating.mean().reset_index()

import scipy.sparse as sparse

# Data conversion for LightFM
user_item_matrix = data.pivot_table(index='user_id', columns='book_id', values='rating', aggfunc='mean').fillna(0)
interactions = sparse.csr_matrix(user_item_matrix.values)

print(user_item_matrix.describe())

# Create the LightFM model
model = LightFM(loss='warp')  # use 'warp' for hybrid recommender models

# Separation of training and test data
train_data, test_data = random_train_test_split(interactions)

# Training the model
model.fit(train_data, epochs=10)

import numpy as np
# Example of generating recommendations for user with user_id 24383
user_id = 24383
n_rec_items = 10
scores = model.predict(user_id, np.arange(user_item_matrix.shape[1]))
top_items = np.argsort(-scores)[:n_rec_items]

print(top_items)

# Load books data and display top recommendations
books_df = pd.read_csv('books.csv')
book_id_to_name = pd.Series(books_df.title.values, index=books_df['id']).to_dict()

recommended_books = [book_id_to_name[item_id] for item_id in top_items]

print(f"Препоръчани книги за потребител с ID {user_id}:")
for rank, book_name in enumerate(recommended_books, 1):
    print(f"{rank}. {book_name}")

# Calculation of RMSE and MAE
from sklearn.metrics import mean_squared_error, mean_absolute_error

def calculate_rmse_mae(model, interactions, test):
    predictions = []
    true_ratings = []
    for user_id in range(interactions.shape[0]):
        scores = model.predict(user_id, np.arange(interactions.shape[1]))
        true = test.tocsr()[user_id].toarray().flatten()
        non_zero_indices = true.nonzero()[0]
        true_ratings.extend(true[non_zero_indices])
        predictions.extend(scores[non_zero_indices])
    rmse = np.sqrt(mean_squared_error(true_ratings, predictions))
    mae = mean_absolute_error(true_ratings, predictions)
    return rmse, mae

rmse, mae = calculate_rmse_mae(model, interactions, test_data)
print(f'RMSE: {rmse}')
print(f'MAE: {mae}')